{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"FinalTraining.csv\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into train and validation DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train, val = train_test_split(train_df, test_size=0.20) #random_state=12)\n",
    "\n",
    "X_train = train.drop(columns=['Classes'])\n",
    "y_train = train['Classes'].values\n",
    "\n",
    "x_val = val.drop(columns=['Classes'])\n",
    "y_val = val['Classes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest model with the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 10,\n",
    "    #'random_state': 11,\n",
    "    #'n_jobs': -1\n",
    "}\n",
    "#insert code here for modelling\n",
    "\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds_train = rf.predict(X_train)\n",
    "rf_preds_val = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a HistGradientBoosting model with the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 10,\n",
    "    #'random_state': 11\n",
    "    #'n_jobs': -1\n",
    "    \n",
    "}\n",
    "\n",
    "hist = HistGradientBoostingClassifier()\n",
    "\n",
    "hist.fit(X_train, y_train)\n",
    "hist_preds_train = hist.predict(X_train.values)\n",
    "hist_preds_val = hist.predict(x_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a gradient boosting model with the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 10,\n",
    "    #'random_state': 11\n",
    "}\n",
    "#insert code here for modelling\n",
    "\n",
    "gbr = GradientBoostingClassifier(**gbr_params)\n",
    "\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_preds_train = gbr.predict(X_train.values)\n",
    "gbr_preds_val = gbr.predict(x_val.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a XGB model with the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "  \n",
    "    #'random_state': 11\n",
    "}\n",
    "#insert code here for modelling\n",
    "\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "\n",
    "\n",
    "xgb.fit(X_train.values, y_train)\n",
    "xgb_preds_train = xgb.predict(X_train.values)\n",
    "xgb_preds_val = xgb.predict(x_val.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a AdaBoost model with the following hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr_params = {\n",
    "    'n_estimators': 1000,\n",
    "    #'random_state': 11\n",
    "}\n",
    "#insert code here for modelling\n",
    "\n",
    "abr = AdaBoostClassifier(**abr_params)\n",
    "\n",
    "\n",
    "abr.fit(X_train, y_train)\n",
    "abr_preds_train = abr.predict(X_train)\n",
    "abr_preds_val = abr.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    " \n",
    "# importing voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    " \n",
    "# Making the final model using voting classifier\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('gbr', gbr), ('abr', abr)], voting='soft')\n",
    " \n",
    "# training all the model on the train dataset\n",
    "final_model.fit(X_train, y_train)\n",
    " \n",
    "# predicting the output on the test dataset\n",
    "pred_final = final_model.predict_proba(x_val)\n",
    "\n",
    " \n",
    "# printing log loss between actual and predicted value\n",
    "print(log_loss(y_val, pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "rf_predicted = rf.predict(x_val)\n",
    "rf_conf_matrix = confusion_matrix(y_val, rf_predicted)\n",
    "rf_acc_score = accuracy_score(y_val, rf_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\n",
    "print(classification_report(y_val, rf_predicted))\n",
    "\n",
    "rf_preds_train = rf.predict(X_train)\n",
    "rf_preds_val = rf.predict(x_val)\n",
    "\n",
    "print('Random Forest:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format(\n",
    "    accuracy_score(y_true=y_train, y_pred=rf_preds_train),\n",
    "    accuracy_score(y_true=y_val, y_pred=rf_preds_val)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Classifier\n",
    "xgb_predicted = xgb.predict(x_val)\n",
    "xgb_conf_matrix = confusion_matrix(y_val, xgb_predicted)\n",
    "xgb_acc_score = accuracy_score(y_val, xgb_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(xgb_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of XGB:\",xgb_acc_score*100,'\\n')\n",
    "print(classification_report(y_val, xgb_predicted))\n",
    "\n",
    "xgb_preds_train = xgb.predict(X_train)\n",
    "xgb_preds_val = xgb.predict(x_val)\n",
    "\n",
    "print('XGB:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format(\n",
    "    accuracy_score(y_true=y_train, y_pred=xgb_preds_train),\n",
    "    accuracy_score(y_true=y_val, y_pred=xgb_preds_val)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "gbr_predicted = gbr.predict(x_val)\n",
    "gbr_conf_matrix = confusion_matrix(y_val, gbr_predicted)\n",
    "gbr_acc_score = accuracy_score(y_val, gbr_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(gbr_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of Gradient Boosting:\",gbr_acc_score*100,'\\n')\n",
    "print(classification_report(y_val, gbr_predicted))\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_preds_train = gbr.predict(X_train)\n",
    "gbr_preds_val = gbr.predict(x_val)\n",
    "\n",
    "print('Gradient Boosting Classfier:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format(\n",
    "    accuracy_score(y_true=y_train, y_pred=gbr_preds_train),\n",
    "    accuracy_score(y_true=y_val, y_pred=gbr_preds_val)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost Classifier\n",
    "abr_predicted = abr.predict(x_val)\n",
    "abr_conf_matrix = confusion_matrix(y_val, abr_predicted)\n",
    "abr_acc_score = accuracy_score(y_val, abr_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(abr_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of AdaBoost:\",abr_acc_score*100,'\\n')\n",
    "print(classification_report(y_val,abr_predicted))\n",
    "\n",
    "abr.fit(X_train, y_train)\n",
    "abr_preds_train = abr.predict(X_train)\n",
    "abr_preds_val = abr.predict(x_val)\n",
    "\n",
    "print('AdaBoost:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format(\n",
    "    accuracy_score(y_true=y_train, y_pred=abr_preds_train),\n",
    "    accuracy_score(y_true=y_val, y_pred=abr_preds_val)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HistGradientBoost Classifier\n",
    "hist_predicted = hist.predict(x_val)\n",
    "hist_conf_matrix = confusion_matrix(y_val, hist_predicted)\n",
    "hist_acc_score = accuracy_score(y_val, hist_predicted)\n",
    "print(\"confusion matrix\")\n",
    "print(hist_conf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy of HistGradientBoost:\",hist_acc_score*100,'\\n')\n",
    "print(classification_report(y_val,hist_predicted))\n",
    "\n",
    "hist.fit(X_train, y_train)\n",
    "hist_preds_train = hist.predict(X_train)\n",
    "hist_preds_val = hist.predict(x_val)\n",
    "\n",
    "print('Hist:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on validation data = {:.4f}'.format(\n",
    "    accuracy_score(y_true=y_train, y_pred=hist_preds_train),\n",
    "    accuracy_score(y_true=y_val, y_pred=hist_preds_val)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_fpr, rf_tpr, rf_threshold = roc_curve(y_val,rf_predicted, pos_label=2)                                                             \n",
    "xgb_fpr, xgb_tpr, xgb_threshold = roc_curve(y_val,xgb_predicted, pos_label=2)\n",
    "abr_fpr, abr_tpr, abr_threshold = roc_curve(y_val,abr_predicted, pos_label=2)\n",
    "gbr_fpr, gbr_tpr, gbr_threshold = roc_curve(y_val,gbr_predicted, pos_label=2)\n",
    "hist_fpr, hist_tpr, hist_threshold = roc_curve(y_val,hist_predicted, pos_label=2) \n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest Classifier')\n",
    "plt.plot(xgb_fpr, xgb_tpr, label='XGB Classifier')\n",
    "plt.plot(gbr_fpr, gbr_tpr, label='Gradient Boosting Classifier')\n",
    "plt.plot(abr_fpr, abr_tpr, label='AdaBoost Classifier')\n",
    "plt.plot(hist_fpr, hist_tpr, label='HistGradientBoosting Classifier')\n",
    "plt.plot([0,1],ls='--')\n",
    "plt.plot([0,0],[1,0],c='.5')\n",
    "plt.plot([1,1],c='.5')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing final model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"FinalTraining.csv\")\n",
    "val_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = val_df.drop(columns=['Classes'])\n",
    "answer_data = val_df['Classes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_filename = \"FinalXGB.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(xgb, file)\n",
    "\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "    \n",
    "# Calculate the accuracy score and predict target values\n",
    "score = pickle_model.score(test_data, answer_data)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "Ypredict = pickle_model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(test_data, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.score(test_data, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr.score(test_data, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.score(test_data, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.score(test_data, answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
